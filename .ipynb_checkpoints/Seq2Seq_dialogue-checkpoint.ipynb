{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Seq 2 Seq Modeling\n",
    "Reference: \n",
    "- https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\n",
    "- https://github.com/aravindpai/How-to-build-own-text-summarizer-using-deep-learning/blob/master/How_to_build_own_text_summarizer_using_deep_learning.ipynb\n",
    "\n",
    "Used dataset:\n",
    "- dialogue\n",
    "- SamSumm\n",
    "https://arxiv.org/src/1911.12237v2/anc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"./data/dialogue/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13818513</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some tomorrow.</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13728867</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in this election.</td>\n",
       "      <td>Olivia: Who are you voting for in this election? \\r\\nOliver: Liberals as always.\\r\\nOlivia: Me too!!\\r\\nOliver: Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13681000</td>\n",
       "      <td>Kim may try the pomodoro technique recommended by Tim to get more stuff done.</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I was going to do lots of stuff but ended up procrastinating\\r\\nTim: What did you plan on doing?\\r\\nKim: Oh you know, uni stuff and unfucking my room\\r\\nK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13730747</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel wants Edward to open his door. Rachel is outside.</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella..\\r\\nrachel: Dont say anything else..\\r\\nEdward: What do you mean??\\r\\nrachel: Open your fu**ing door.. I'm outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13728094</td>\n",
       "      <td>Sam is confused, because he overheard Rick complaining about him as a roommate. Naomi thinks Sam should talk to Rick. Sam is not sure what to do.</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam: i don't know what to do :-/\\r\\nNaomi: what did he say??\\r\\nSam: he was talking on the phone with someone\\r\\nSam: i don't know who\\r\\nSam: and he was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0  13818513   \n",
       "1  13728867   \n",
       "2  13681000   \n",
       "3  13730747   \n",
       "4  13728094   \n",
       "\n",
       "                                                                                                                                             summary  \\\n",
       "0                                                                                           Amanda baked cookies and will bring Jerry some tomorrow.   \n",
       "1                                                                                      Olivia and Olivier are voting for liberals in this election.    \n",
       "2                                                                      Kim may try the pomodoro technique recommended by Tim to get more stuff done.   \n",
       "3                                                  Edward thinks he is in love with Bella. Rachel wants Edward to open his door. Rachel is outside.    \n",
       "4  Sam is confused, because he overheard Rick complaining about him as a roommate. Naomi thinks Sam should talk to Rick. Sam is not sure what to do.   \n",
       "\n",
       "                                                                                                                                                                                                  dialogue  \n",
       "0                                                                                                       Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)  \n",
       "1                                                                                    Olivia: Who are you voting for in this election? \\r\\nOliver: Liberals as always.\\r\\nOlivia: Me too!!\\r\\nOliver: Great  \n",
       "2  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I was going to do lots of stuff but ended up procrastinating\\r\\nTim: What did you plan on doing?\\r\\nKim: Oh you know, uni stuff and unfucking my room\\r\\nK...  \n",
       "3                                        Edward: Rachel, I think I'm in ove with Bella..\\r\\nrachel: Dont say anything else..\\r\\nEdward: What do you mean??\\r\\nrachel: Open your fu**ing door.. I'm outside  \n",
       "4  Sam: hey  overheard rick say something\\r\\nSam: i don't know what to do :-/\\r\\nNaomi: what did he say??\\r\\nSam: he was talking on the phone with someone\\r\\nSam: i don't know who\\r\\nSam: and he was ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['dialogue'],inplace=True) #dropping duplicates\n",
    "data.dropna(axis=0,inplace=True) #dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14265 entries, 0 to 14731\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        14265 non-null  object\n",
      " 1   summary   14265 non-null  object\n",
      " 2   dialogue  14265 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 445.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Convert everything to lowercase\n",
    "- Remove HTML tags\n",
    "- Contraction mapping\n",
    "- Remove (‘s)\n",
    "- Remove any text inside the parenthesis ( )\n",
    "- Eliminate punctuations and special characters\n",
    "- Remove stopwords\n",
    "- Remove short words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['dialogue']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amanda baked cookies want jerry sure amanda bring tomorrow',\n",
       " 'olivia voting election oliver liberals always olivia oliver great',\n",
       " 'tim hi kim bad mood tbh going lots stuff ended procrastinating tim plan kim oh know uni stuff unfucking room kim maybe tomorrow move ass everything kim going defrost fridge instead shopping eat defrosted veggies tim stuff recommend pomodoro technique use breaks chores tim really helps kim thanks maybe tim also like using post kaban style',\n",
       " 'edward rachel think ove bella rachel dont say anything else edward mean rachel open fu ing door outside',\n",
       " 'sam hey overheard rick say something sam know naomi say sam talking phone someone sam know sam telling happy naomi damn sam saying like roommate naomi wow feel sam thought good rommate sam nice place naomi true man naomi used love living moved boyfriend naomi know saying sam naomi honestly bothering much talk naomi see going sam want get kind confrontation though sam maybe let go sam see goes future naomi choice sam naomi would talk clear air']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amanda baked cookies and will bring jerry some tomorrow',\n",
       " 'olivia and olivier are voting for liberals in this election',\n",
       " 'kim may try the pomodoro technique recommended by tim to get more stuff done',\n",
       " 'edward thinks he is in love with bella rachel wants edward to open his door rachel is outside',\n",
       " 'sam is confused because he overheard rick complaining about him as roommate naomi thinks sam should talk to rick sam is not sure what to do',\n",
       " 'wyatt reminds neville his wedding anniversary is on the th of september neville wife is upset and it might be because neville forgot about their anniversary',\n",
       " 'john did not show up for class due to some work issues with his boss cassandra his teacher told him which exercises to do and which chapter to study they are going to meet up for beer sometime this week after class',\n",
       " 'sarah sends james an instrumental song he might like james knows the song the brain connects the songs to the context they were played in and brings to mind the associated memories',\n",
       " 'noah wants to meet he quit his job because his boss was dick',\n",
       " 'matt invites agnes for date to get to know each other better they will go to the georgian restaurant in kazimierz on saturday at pm and he will pick her up on the way to the place']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty rows\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Understand distribution of words to fix max_length for summary and review\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12149467190128996\n"
     ]
    }
   ],
   "source": [
    "# Understand proportion of length of summaries < 8\n",
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=70\n",
    "max_summary_len=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select reviews & summaries with determined max_length\n",
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply unique START and END token\n",
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% Training data and 10% holdout set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Tokenizer for reviews on training data\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 62.59038583906982\n",
      "Total Coverage of rare words: 5.529838955567259\n"
     ]
    }
   ],
   "source": [
    "# Rarewords and coverage\n",
    "# -- threshold is 4 => Below 4 is rareword\n",
    "thresh=4\n",
    "\n",
    "cnt=0 # no. of rare words below threshold\n",
    "tot_cnt=0 # size of vocabulary (unique words in text)\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer with Top most common words\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) # tot_cnt - cnt gives me the top most common words\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6468"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 78.16407730200834\n",
      "Total Coverage of rare words: 9.07483157646969\n"
     ]
    }
   ],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9143, 9143)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether word count with start token is == length of training data\n",
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Rows with only START & END token\n",
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Return Sequences = True: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
    "- Return State = True: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
    "- Initial State: This is used to initialize the internal states of the LSTM for the first timestep\n",
    "- Stacked LSTM: Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence. I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 70, 100)      646800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 70, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 70, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    230600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 70, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 2306)   1385906     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,848,406\n",
      "Trainable params: 4,848,406\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: sparse categorical cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Early Stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9141 samples, validate on 1014 samples\n",
      "Epoch 1/15\n",
      "9141/9141 [==============================] - 483s 53ms/sample - loss: 4.0912 - val_loss: 3.2601\n",
      "Epoch 2/15\n",
      "9141/9141 [==============================] - 430s 47ms/sample - loss: 3.2867 - val_loss: 3.0921\n",
      "Epoch 3/15\n",
      "9141/9141 [==============================] - 424s 46ms/sample - loss: 3.0975 - val_loss: 2.9092\n",
      "Epoch 4/15\n",
      "9141/9141 [==============================] - 431s 47ms/sample - loss: 2.9792 - val_loss: 2.8485\n",
      "Epoch 5/15\n",
      "9141/9141 [==============================] - 431s 47ms/sample - loss: 2.9180 - val_loss: 2.7981\n",
      "Epoch 6/15\n",
      "9141/9141 [==============================] - 417s 46ms/sample - loss: 2.8628 - val_loss: 2.7395\n",
      "Epoch 7/15\n",
      "9141/9141 [==============================] - 438s 48ms/sample - loss: 2.7924 - val_loss: 2.6805\n",
      "Epoch 8/15\n",
      "9141/9141 [==============================] - 433s 47ms/sample - loss: 2.7365 - val_loss: 2.6660\n",
      "Epoch 9/15\n",
      "9141/9141 [==============================] - 447s 49ms/sample - loss: 2.6968 - val_loss: 2.6156\n",
      "Epoch 10/15\n",
      "9141/9141 [==============================] - 433s 47ms/sample - loss: 2.6594 - val_loss: 2.6022\n",
      "Epoch 11/15\n",
      "9141/9141 [==============================] - 438s 48ms/sample - loss: 2.6282 - val_loss: 2.5600\n",
      "Epoch 12/15\n",
      "9141/9141 [==============================] - 426s 47ms/sample - loss: 2.5906 - val_loss: 2.5334\n",
      "Epoch 13/15\n",
      "9141/9141 [==============================] - 424s 46ms/sample - loss: 2.5580 - val_loss: 2.5032\n",
      "Epoch 14/15\n",
      "9141/9141 [==============================] - 431s 47ms/sample - loss: 2.5210 - val_loss: 2.4811\n",
      "Epoch 15/15\n",
      "9141/9141 [==============================] - 419s 46ms/sample - loss: 2.4880 - val_loss: 2.4638\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=15,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from keras.models import load_model\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# ## Saving Models\n",
    "# # model.save(\"./test/reviewmodel.h5\")\n",
    "\n",
    "# ## Loading Model\n",
    "# model = load_model(\"./test/reviewmodel.h5\", custom_objects={'AttentionLayer': AttentionLayer})\n",
    "# model.summary()\n",
    "\n",
    "# # Variables for Decoder\n",
    "# encoder_inputs = model.inputs[0]\n",
    "# decoder_inputs = model.inputs[1]\n",
    "# decoder_outputs = model.outputs\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# model.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand diagnostic plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionary to convert index into words (target & source vocab)\n",
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "\n",
    "## Saving Models\n",
    "encoder_model.save(\"./encoder_model1.h5\")\n",
    "decoder_model.save(\"./decoder_model1.h5\")\n",
    "\n",
    "## Loading Model\n",
    "# encoder_model = load_model(\"./encoder_model1.h5\", custom_objects={'AttentionLayer': AttentionLayer})\n",
    "# decoder_model = load_model(\"./decoder_model1.h5\", custom_objects={'AttentionLayer': AttentionLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference process\n",
    "1. Encode the entire input sequence and initialize the decoder with internal states of the encoder\n",
    "2. Pass <start> token as an input to the decoder\n",
    "3. Run the decoder for one timestep with the internal states\n",
    "4. The output will be the probability for the next word. The word with the maximum probability will be selected\n",
    "5. Pass the sampled word as an input to the decoder in the next timestep and update the internal states with the current time step\n",
    "6. Repeat steps 3 – 5 until we generate <end> token or hit the maximum length of the target sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int sequence --> word sequence\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: jacob rob leave desk robert yup man jacob stupid robert take leave ann jacob would great nice thanks robert problem \n",
      "Original summary: jacob left his on the desk jacob will take it for him and leave at ann \n",
      "Predicted summary:  is to the the the the the the\n",
      "\n",
      "\n",
      "Review: macey really sad jairo oh macey go jairo sure macey usually hang friends jairo go restaurant sit friend home macey prefer lot friends close ones jairo friends closer compared others macey hmm jairo dont worry figure something macey go ice cream jairo yeah macey would outside house sharp pm \n",
      "Original summary: is sad and will go to the ice cream will be at house at pm \n",
      "Predicted summary:  and will come to the the the the the\n",
      "\n",
      "\n",
      "Review: jen chicken tim shit forgot tim jen late get something else store tim sorry jen prob see ya \n",
      "Original summary: tim forgot to take the chicken out to jen will get something else at the store \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: veronica pedro asked today alice tell us veronica well much say sat next class finished asked wanted something evening cara want something veronica hahaha see new film jude law cara going cinema veronica yea maybe drinks alice let us know goes drinks \n",
      "Original summary: pedro asked veronica out they are going to the cinema and maybe for some drinks \n",
      "Predicted summary:  and is to the the the the the the\n",
      "\n",
      "\n",
      "Review: bob hi sandra sandra good hear sandra feeling bob little better sandra hospital bob quite right considering sandra take good care bob nothing complain really sandra food bob could make improvements sandra bad ha bob let us say enjoy sandra bring food tonight sandra eat bob practically nothing bother sandra must something bob well could bring fruit suppose sandra want bob perhaps couple bananas sandra problem see work \n",
      "Original summary: sandra is at hospital and is feeling little better now bob will bring her some when he her after work \n",
      "Predicted summary:  is to the the the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: rose dog run away rose know help please rose bye donald actually anything haha donald well ends well donald bye bye \n",
      "Original summary: wendy brought back her dog that rose thought was lost \n",
      "Predicted summary:  the and and are going to the the the\n",
      "\n",
      "\n",
      "Review: jane jane jane lucy linda definitely look stunning \n",
      "Original summary: jane sent two photos lucy and linda advise her for the first choice \n",
      "Predicted summary:  the to the the the the\n",
      "\n",
      "\n",
      "Review: gabe cat staring eve feed gabe staring looks hungry eve trust trying trick better man gabe \n",
      "Original summary: gabe should not feed the cat \n",
      "Predicted summary:  the and and are not to the the the\n",
      "\n",
      "\n",
      "Review: melanie friend still sleeps teddy bear kate weird melanie right kate maybe kid melanie jesus christ never thought way \n",
      "Original summary: kate finds it weird that melanie friend keeps sleeping with her teddy despite she is years old kate suspects that the girl might have been as child \n",
      "Predicted summary:  the to the the the the the the\n",
      "\n",
      "\n",
      "Review: john still angry mary yes john honey sorry fault mary never mind \n",
      "Original summary: mary is still angry but it was not \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: jarvis thank much sent jarvis wife drank coffee son took cake jarvis jarvis dustin happy hear dustin treated well last time thinking dustin pleased good time family jarvis thanks \n",
      "Original summary: had good time with his family he is happy about picture dustin has sent him he sends some photos to dustin \n",
      "Predicted summary:  is to the the new new the the the\n",
      "\n",
      "\n",
      "Review: kirk crazy kirk two front row tickets basketball game tonight cannot give away kirk either want cannot go edward edward front row tickets edward take kirk really kirk glad going waste kirk know liked basketball kirk otherwise would first list edward love favorite sport edward really wanted go game edward kirk taking edward friend tony edward really basketball \n",
      "Original summary: has front row tickets to give away for the basketball game tonight edward is willing to go and he will take his friend tony who is into basketball too \n",
      "Predicted summary:  and will come to the the the the the the the\n",
      "\n",
      "\n",
      "Review: cathy hey emma cathy place around pm emma hi cathy ok waiting annie cathy annie emma great growing fast see cathy main station emma east one emma waiting station cathy oh really place find way emma problem really emma weather beautiful planning take walk annie anyway cathy ok cannot wait finally see emma likewise \n",
      "Original summary: cathy coming to emma place emma and annie will wait for her at the station \n",
      "Predicted summary:  and will come to the the the the the\n",
      "\n",
      "\n",
      "Review: chandler hey restaurant wanna eat something monica right chandler two broke monica grab lasagnia chandler lasagnia survive lasagnia monica okay okay bring cheese cake cheese factory chandler haha like monica hahaha tomorrow start diet xd \n",
      "Original summary: chandler is at the restaurant two broke he will grab some for monica and cheese cake from cheese monica plans to start diet tomorrow \n",
      "Predicted summary:  and will come to the the the the the\n",
      "\n",
      "\n",
      "Review: liam guys treating terry could better john maybe bit sun could better helmut want join us liam yup helmut knew liam hehehe terry made change mind liam money money john course always money liam studying free great scholarships john exactly john liam know yet \n",
      "Original summary: terry john and are studying in and they are with that liam thinking about joining them there \n",
      "Predicted summary:  and will come to the the the the the\n",
      "\n",
      "\n",
      "Review: jake jake think enough kitchen miriam size jake length width monique guess enough monique price jake miriam really lot monique yep lot jake looking something else \n",
      "Original summary: jake is wondering if it is enough for their kitchen it is in in and costs miriam and think it is too expensive \n",
      "Predicted summary:  the new the the the the the the\n",
      "\n",
      "\n",
      "Review: bonny hi clyde doin something clyde really bonny fucking bored death clyde let us something bonny yeah let us clyde bonny know let us meet clyde yeah pick bonny think something \n",
      "Original summary: and are going to spend time together \n",
      "Predicted summary:  and will come to the the the the the\n",
      "\n",
      "\n",
      "Review: barry vodka disco marty sure barry place marty ok \n",
      "Original summary: barry and marty decide to have some vodka and they will meet at barry \n",
      "Predicted summary:  is to the the the the\n",
      "\n",
      "\n",
      "Review: william going home christmas brian staying italy amy going paris visit friend william travel alone time \n",
      "Original summary: brian and amy are not going home for christmas so william will travel alone \n",
      "Predicted summary:  and is going to the the the the\n",
      "\n",
      "\n",
      "Review: samantha going start dating since paul becky hahaha becky thanks samantha see becky wait moment go date sam set samantha samantha good memory becky could forget sam samantha cute becky must agree \n",
      "Original summary: becky arranged date between samantha and sam samantha and becky think sam is attractive \n",
      "Predicted summary:  the and and are going to the the the the\n",
      "\n",
      "\n",
      "Review: angie send picture cat louisa angie thx \n",
      "Original summary: sends angie picture of her cat \n",
      "Predicted summary:  the and and are not to the the the\n",
      "\n",
      "\n",
      "Review: liam plates sean plates liam hundreds plastic plates left theresa gil bought gil yes sorry forgot gil need liam maybe offer owner place gil \n",
      "Original summary: gil bought lot of but he does not need them he will offer them to the place \n",
      "Predicted summary:  is to the the the the the the the\n",
      "\n",
      "\n",
      "Review: marie party good trevor yes also prepared amazing food right cory hahah yes sausages drinks remember name dumplings marie marie good \n",
      "Original summary: marie trevor and cory liked the party there were sausages drinks and liked the \n",
      "Predicted summary:  the to the the the the the the\n",
      "\n",
      "\n",
      "Review: agatha everyone please send actual physical cause want send invitations emily let begin ana cannot believe big day coming got engaged swear agatha know excited aggie check email wedding wife wants know emily right business haha agatha info sent together ana deadline agatha gimmie address send invitation soon find haha giving details \n",
      "Original summary: agatha is getting married and needs emily ana and to send them \n",
      "Predicted summary:  and is to the the the the the the the\n",
      "\n",
      "\n",
      "Review: kris hiram kris know well hiram ohhh noooo please tell broke house kris old lady yesss hiram omg crazy somebody saw kris careful hiram kris extremely clean many pieces art looks like museum hiram haha expected dead people ghosts kris hah stole hiram kris hiram youre sick xd kris plus maybe find start thinking somebody house hiram even sick \n",
      "Original summary: kris broke into lady house and stole as \n",
      "Predicted summary:  is to the the new new the the the the\n",
      "\n",
      "\n",
      "Review: angie alive mike angie mike sick day angie never drinking mike sick party though xd angie mike \n",
      "Original summary: mike and angie are after party \n",
      "Predicted summary:  the to the the the the the the\n",
      "\n",
      "\n",
      "Review: john warn children come without might rain john rain soon linda ok \n",
      "Original summary: it is going to so linda must make sure the children wear their \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: abigail got phone call abigail guess alex abigail cancelled alex abigail yes alex despicable abigail right \n",
      "Original summary: abigail has just got phone call and he cancelled abigail and alex think it was very \n",
      "Predicted summary:  the new the new new the the\n",
      "\n",
      "\n",
      "Review: henry hello grace hello grace owe pleasure son henry well shopping right henry might need advice grace thought grace henry know shirt choose henry henry grace hmm tough choice henry know turned mother grace tbh pink one suits better green one henry thought wanted confirmation henry grace splendid need anything else start dancing class mins henry nope thanks fun \n",
      "Original summary: henry is shopping for shirt and asks grace for advice she likes the pink shirt more than the green one grace has dance class in minutes \n",
      "Predicted summary:  is to the the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: kenny exactly final submission deadline find anywhere sooooo far behind work time keep searching help anna drama next sunday midnight joan confirm please remember essay always around deadlines joan basically put away whole day sunday submission always works end might really wait long time try times done anna kenny thanks much \n",
      "Original summary: the essay has to be through which always takes some time around \n",
      "Predicted summary:  is to the the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: raymond reminder bro carry documents reddington need worry thats first thing put bag raymond id passport rest reddington yes raymond okay reddington cant wait interview raymond nervous reddington little bit raymond bt fine reddington feeling okay raymond god first reddington yeah god first raymond later reddington okay \n",
      "Original summary: raymond reminds to pack documents up they will have an interview \n",
      "Predicted summary:  is to the the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: michael hi concert yesterday michael sorry could make ursula good michael come ursula one came michael wtf one ursula soul michael oh gawd im sorry ursula ok played anyway get paid course michael ursula indeed \n",
      "Original summary: michael could not come to the concert yesterday nobody came so ursula did not get paid \n",
      "Predicted summary:  is to the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: tom size gina fred tom looking gift found nice sara say depends shop tom thanks \n",
      "Original summary: tom is buying for gina gina is size or \n",
      "Predicted summary:  the and and are not to the the the\n",
      "\n",
      "\n",
      "Review: dixie speak work finish bring dixie nowadays send email ah sorry know dixie understand working last dance dance try get used changed market haha \n",
      "Original summary: has not worked much after dance dance and is him to the business \n",
      "Predicted summary:  the and and are to the the the the\n",
      "\n",
      "\n",
      "Review: marie fran inside marie running fran ok downstairs table left \n",
      "Original summary: fran is waiting for marie inside she is coming \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: toby seen best movie peter toby yes richard samuel anything surprising toby star born example richard expect toby \n",
      "Original summary: the oscar for the best movie are already out \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: veronica left school earlier today dad veronica period feel terrible \n",
      "Original summary: veronica left school early today because of her period \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: hilary charity ball boring year dick glad go maureen worse worse maureen last year also great hilary best one maureen much fun dick good old days \n",
      "Original summary: this year charity ball was boring the best one was in \n",
      "Predicted summary:  is to the the the the the the\n",
      "\n",
      "\n",
      "Review: barbara coming dad birthday charlie yes charlie time exactly barbara maybe bit later charlie ok thomas afraid make \n",
      "Original summary: barbara is coming to dad birthday at around charlie will be there but thomas will not make it \n",
      "Predicted summary:  is to the the the the the the\n",
      "\n",
      "\n",
      "Review: kenneth gym today anyone susie work evan already chad way kenneth ok see evan leaving evan done kenneth chad chad yeah mins kenneth ok susie evan fault crappy job xd kenneth chad xd \n",
      "Original summary: susie is at work evan is at the gym but he is leaving in minutes chad and kenneth will meet at the gym in minutes \n",
      "Predicted summary:  and will come to the the the the the\n",
      "\n",
      "\n",
      "Review: justin look dont let take lunch today cecilia haha know justin justin im real im kidding around cecilia youre im justin cool ill pick noon cecilia sure noon fine justin alright \n",
      "Original summary: justin will pick cecilia up at noon today and they will go for lunch \n",
      "Predicted summary:  and is to go to the the the the\n",
      "\n",
      "\n",
      "Review: mary groceries way home charles tired mary please make charles ok need mary store go charles matter mary ok get something breakfast supper know bread cheese ham maybe charles want make pancakes today mary yes charles \n",
      "Original summary: charles will get groceries for mary and make pancakes today \n",
      "Predicted summary:  and will come to the the the the the\n",
      "\n",
      "\n",
      "Review: rick wanna come watch new morty today rick ok let know morty maybe next week morty let know \n",
      "Original summary: rick and may meet next week to watch the new season of the \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: sam new yet named patrick audrey sam already considering patrick wondering always call cars names sam quite funny patrick ok get one looks like bernadette sam patrick sam think would perfect patrick choice personal think sam right patrick maybe take time get know car sam great idea \n",
      "Original summary: sam is going to take some time before his car \n",
      "Predicted summary:  and is going to the the the the the the\n",
      "\n",
      "\n",
      "Review: mark mate grab coffee way back home john sure probs shall mark thanks much appreciated \n",
      "Original summary: john will grab some coffee for mark on his way back home \n",
      "Predicted summary:  and will be to the the the the\n",
      "\n",
      "\n",
      "Review: seen weather forecast martin yes going warm sunny damn already pack summer stuff \n",
      "Original summary: martin has seen the weather and it is going to be hot and sunny is angry because she already packed all her summer stuff \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: arianna hello sorry seem lost confirmation email reference number chance could robert hello problem book go name arianna booked coach birmingham robert moment please robert please find attached confirmation booking need show driver getting bus robert arianna great thank robert worries enjoy trip \n",
      "Original summary: will need to show the booking to the driver \n",
      "Predicted summary:  is to the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: ruby aaron ruby watch aaron awww remembered ruby sure aaron thank awesome ruby mention aaron went trouble ruby yes stupid aaron words fail ruby think first time ever aaron lol \n",
      "Original summary: ruby sends aaron video as surprise gift \n",
      "Predicted summary:  is to the the the the the the the\n",
      "\n",
      "\n",
      "Review: karen really want go one wants go john texting say go barking wrong tree karen texting karen ok texting karen come come come come john one wants go reason john boring one likes karen bad friend lol \n",
      "Original summary: karen wants john to go with her as nobody else wants to do it john is not willing to go with her \n",
      "Predicted summary:  and is going to the the the the the the\n",
      "\n",
      "\n",
      "Review: john know going next us united kevin idea john trump said friday going kelly knight john current canada kevin good know think good choice john idea know passing time john says rather best choice kevin see \n",
      "Original summary: john tells kevin that trump might kelly as the next us to the \n",
      "Predicted summary:  is to the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: frank hi joe need help joe need frank know bucks till next week need joe well gonna easy best wait till tomorrow frank let know asap gonna work joe \n",
      "Original summary: frank lent joe bucks till next week but needs it now frank will try to pay him back tomorrow \n",
      "Predicted summary:  is to the the the the the the the\n",
      "\n",
      "\n",
      "Review: liam neil im liam stay neil \n",
      "Original summary: neil is at charlie \n",
      "Predicted summary:  is to the the the the\n",
      "\n",
      "\n",
      "Review: katie hey shop right set two colors something like indigo light grey one would prefer suzanne hm charlie guess indigo one arnold grey things apartment tho suzanne indigo dress katie guys supposed helping charlie think recall saying likes indigo suzanne plus nice accent otherwise apartment arnold indigo katie taking indigo thanks help suzanne time \n",
      "Original summary: katie set for her friend \n",
      "Predicted summary:  is to the the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: cherry hey finished book gave richard yes amazing thank cherry glad liked something read right finishing catch absolutely brilliant richard read brilliant indeed yeah following classics right cherry richard hate admit never read master cherry whoa way although kind jealous still ahead cherry way set reading challenge year richard sure thing goal last year managed read cherry though may see \n",
      "Original summary: richard has read book gave him richard has never read and reading is to read books this year \n",
      "Predicted summary:  is to the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: james could borrow bucks kathleen james lost bet need pay today kathleen betting much less money kathleen sorry want part \n",
      "Original summary: james wants to borrow dollars from she refused to do that \n",
      "Predicted summary:  the to the the the the the the\n",
      "\n",
      "\n",
      "Review: amber abby okay news abigail yeah want talk faith think know means amber worry honey alone faith exactly let us meet abigail thank need talk faith know let us leave abigail meet tonight amber sure abigail feel like going faith okay come place time abigail home whenever ready \n",
      "Original summary: abigail needs support amber and faith will come to her place \n",
      "Predicted summary:  and is to the the the the the the\n",
      "\n",
      "\n",
      "Review: kouki starving jake jake stuff rn kouki hurry jake im done soon kouki jake eat kouki downstairs cafeteria jake \n",
      "Original summary: jake and will have something to eat at the cafeteria downstairs \n",
      "Predicted summary:  is to the the the the the the\n",
      "\n",
      "\n",
      "Review: greta want dinner mark maybe fish greta chips mark fish without chips greta right forgot talking greta need buy way home mark everything fish \n",
      "Original summary: mark wants fish and for dinner he will get some for it on his way home \n",
      "Predicted summary:  is to the the the the the the\n",
      "\n",
      "\n",
      "Review: erin ok called fabric shop tim erin guy erin talk guy dress tim well maybe perfect person conversation erin oh well seem eager talk honest \n",
      "Original summary: erin called the shop she did not like the fact that it was man who the phone \n",
      "Predicted summary:  the and and are going to the the the the\n",
      "\n",
      "\n",
      "Review: kristen kristen dana bit would say sexy ray yeah mee kristen exactly dana going kristen prom dana oh ok dana thought work sth wrong going work like xd ray yeah would mind either hahaha seriously prom perfect ray dana kristen \n",
      "Original summary: kristen is going to the she her outfit with dana ray and will \n",
      "Predicted summary:  is to the the the the the the the the\n",
      "\n",
      "\n",
      "Review: laura george highway laura exactly george believe already state laura ok \n",
      "Original summary: george is on the probably in the of \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: jaylee got milk raven yeah fridge jaylee raven yellow bottle jaylee water also raven yes jaylee thanx raven welcome \n",
      "Original summary: there is milk and water in the fridge \n",
      "Predicted summary:  is to the the the the the the\n",
      "\n",
      "\n",
      "Review: susan bored tom sleeping eyes open prof realise linda tom nice \n",
      "Original summary: susan tom and linda are bored at the university lecture linda sends photo of her \n",
      "Predicted summary:  the and and are going to the the the\n",
      "\n",
      "\n",
      "Review: oscar check david lol linda okay quit job decided dress spiderman last day linda lame david ugh linda like funny oscar linda trolling kinda cute david seriously funny \n",
      "Original summary: he as spiderman on his last day at work david thinks it is funny \n",
      "Predicted summary:  is to the the the the the the the\n",
      "\n",
      "\n",
      "Review: claudia hey anyone discount code kelsey shoes claudia ok order cute boots kelsey go send us pics get claudia thank bunch \n",
      "Original summary: shared her discount code with claudia \n",
      "Predicted summary:  the to the the the the the the the\n",
      "\n",
      "\n",
      "Review: ben hey mon remember code monica mean alarm code ben yep monica hmm sure ben tuesday sb help wed monica hmm aaron yeah aaron write wednesday aaron case monica great tx ben ok ben make sure enter room without monica yeah try unlike last time xd aaron xd aaron \n",
      "Original summary: somebody will come help ben on tuesday aaron will write down the code for ben \n",
      "Predicted summary:  is to the the the the the the the the the the\n",
      "\n",
      "\n",
      "Review: aurora think eli get haircut look absolutely stunning babe aurora yes thank think cut hair short eli eli look perfect \n",
      "Original summary: aurora has new haircut \n",
      "Predicted summary:  the new the the new the the\n",
      "\n",
      "\n",
      "Review: lilyana hallie hallie girl nails look fab hallie done lilyana actually hallie pulling leg looks like pro work lilyana thanks lilyana sometimes want hallie sounds great never creative comes nails haha lilyana oh looked inspiration instagram really recommend nail art photos \n",
      "Original summary: did her nails herself likes them she offered to do nails for her looked for on and \n",
      "Predicted summary:  the and and are going to the the the the\n",
      "\n",
      "\n",
      "Review: josh hey guys got roll sam may enough mountains anymore josh dont bore sam real josh got check sam josh map exactly destination sam unbelievable josh come go sam inform others \n",
      "Original summary: josh encourages sam to sam will inform the rest of friends \n",
      "Predicted summary:  is to the the the the the the the the\n",
      "\n",
      "\n",
      "Review: lottie find last easter bunny maria get biggest present sorry hun lottie wanted spent whole day looking maria sorry rules \n",
      "Original summary: maria won get the present because she didn find the last \n",
      "Predicted summary:  the to the the the the the the\n",
      "\n",
      "\n",
      "Review: joe watching film abigail mom already asleep mia watching good place joe ah okay \n",
      "Original summary: abigail and mia are watching the good place \n",
      "Predicted summary:  the and and are not to the the the\n",
      "\n",
      "\n",
      "Review: sophie jay oh yeah jay jay tonight gonna sophie getting ready babe sophie jay damn girl lookin hot tonight jay \n",
      "Original summary: jay and sophie are getting ready for tonight \n",
      "Predicted summary:  and will be to the the the the\n",
      "\n",
      "\n",
      "Review: donna help donna donna know mean previous projects martha hey help pm ok martha meeting donna ok sure whenever \n",
      "Original summary: martha is going to help donna with this after pm as she is in meeting \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: jack andrew trudy went see game jack yes jack last saturday andrew watched tv andrew idea went jack amy surprised got us tickets trudy amy great jack jack game awesome jack important jack th league \n",
      "Original summary: jack and amy went to the match on last saturday \n",
      "Predicted summary:  is to the the the the the the the the\n",
      "\n",
      "\n",
      "Review: william gooood ava hello william ava breakfast william oh ok make ava yes always join william ok going get plane going italy instead haha ava good hehe \n",
      "Original summary: ava is making breakfast \n",
      "Predicted summary:  is to the the the the the the\n",
      "\n",
      "\n",
      "Review: linda time leaving paula yes linda around paula something like depends traffic linda ok waiting \n",
      "Original summary: paula is leaving at pm linda is waiting for her \n",
      "Predicted summary:  and will be to the the the the\n",
      "\n",
      "\n",
      "Review: christopher smith good morning welcome new website may help alexander williams good morning wondering samsung galaxy stock christopher smith yes samsung galaxy samsung galaxy one would prefer alexander williams prefer samsung galaxy may ask price christopher smith yes course costs alexander williams opening hours christopher smith mon sat pm sun pm alexander williams thank much christopher smith welcome \n",
      "Original summary: alexander is interested in samsung christopher smith confirms it is in stock and costs they are open am pm am pm \n",
      "Predicted summary:  and is to the the the the the the the\n",
      "\n",
      "\n",
      "Review: beryl know good idea linette beryl like surprises linette oh come great beryl linette birthday happy beryl think linette let us try least beryl try ofc linette ok handle beryl ok wish start linette let us meet discuss beryl ok drop linette great see \n",
      "Original summary: and are planning surprise birthday party for him will come to apartment to discuss it \n",
      "Predicted summary:  is to the the the the the the the the\n",
      "\n",
      "\n",
      "Review: rachel rachel season casa de papel lucy really rachel yup rachel guess going play sara berlin sure sara best series ever lucy hope really soon lucy cause got nothing watch watched literally everything sara hahahah \n",
      "Original summary: rachel lucy and sara are excited about the season of la de in and the return of berlin \n",
      "Predicted summary:  the and and are going to the the the the\n",
      "\n",
      "\n",
      "Review: westin watched beasts wild izayah westin know yet izayah asking westin haha wanna watch fantasy movie izayah hmm movies westin neither one seems interesting izayah enjoy westin thanks anyway izayah haha ok \n",
      "Original summary: and have never seen beasts of the is considering giving it try \n",
      "Predicted summary:  the and and are going to the the the the\n",
      "\n",
      "\n",
      "Review: lang xbox sale hugo youve looking one since hugo last month lang yeah hugo gonna take offer lang im thinking lang mean would spend extra stuff lang good deal lang think hugo good hugo say go lang im going look condition tomorrow lang care join hugo sure text ill show lang cool \n",
      "Original summary: found an on he is been looking for it for month hugo and are meeting tomorrow to condition \n",
      "Predicted summary:  and is going to the the the the the the the the\n",
      "\n",
      "\n",
      "Review: bill hey guys going training today yeah bill would mind taking michael back sure problem something wrong car bill everything fine somewhere cannot pick today ok problem bill thanks lot \n",
      "Original summary: will go for training today he will pick up michael with him because bill has to be somewhere at \n",
      "Predicted summary:  and will come to the the the the the\n",
      "\n",
      "\n",
      "Review: patty patty nice day ben thx \n",
      "Original summary: patty wishes ben nice day \n",
      "Predicted summary:  is to the the the the\n",
      "\n",
      "\n",
      "Review: isabel hey best jada mean isabel dont know jada try cambridge isabel ok tx \n",
      "Original summary: isabel will check cambridge and per recommendation \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: john yo chris alex fuck chris guess john john get butt fuck egypt \n",
      "Original summary: alex and john are what is on chris picture and where he got it from \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: evelyn hi evelyn need honest opinion look good evelyn sophia looks ok colour disaster sophia would make complaint sophia sorry evelyn ok thanks lot thought sure sophia good luck \n",
      "Original summary: sophia does not approve evelyn hair color she suggests evelyn should make evelyn is going to do so \n",
      "Predicted summary:  is to the the new new the the the\n",
      "\n",
      "\n",
      "Review: sean hey connor hi sean connor bored sean maybe cinema connor great idea sean know \n",
      "Original summary: sean and connor agreed to go to the cinema \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: jack coming minutes jason ok lucy buy beer coop lucy running beer lucy vodka jack ok jack anything else lucy thanks \n",
      "Original summary: jack arriving in minutes he will buy some beer and vodka in the at lucy request \n",
      "Predicted summary:  and will be to the the the the\n",
      "\n",
      "\n",
      "Review: blake george blake mom calling supper blake cannot hear yelling george shit im coming downstairs blake better \n",
      "Original summary: mom is calling george to come for supper he is coming now \n",
      "Predicted summary:  is to the the the the the\n",
      "\n",
      "\n",
      "Review: noah going gym jake sth joe would go last time gym know december xdd noah thats go joe xdddd ok go jake good call boys \n",
      "Original summary: noah is going to the gym at jake cannot join because he has something to do and he has not been at the gym long joe will join noah \n",
      "Predicted summary:  and will come to the the the the\n",
      "\n",
      "\n",
      "Review: pauline pauline look cute cat kevin gorgeous pauline haha pauline come visit kevin well thanks kevin planning pop pauline anytime kevin anytime \n",
      "Original summary: pauline would like kevin to visit her and her cat \n",
      "Predicted summary:  the new the new new the the the\n",
      "\n",
      "\n",
      "Review: carrie let us something want come mine play game freddie would love coming start carrie laura alex planning pm freddie work pm freddie earliest make pm ok carrie sure wait probs freddie awesome carrie btw got new expansion pack freddie one carrie freddie yeah good one carrie yet freddie think like carrie hope xo carrie see mine take care \n",
      "Original summary: carrie invited freddie and some other friends to play he works late but they will wait for him freddie has new for the game \n",
      "Predicted summary:  and will come to the the the the the the\n",
      "\n",
      "\n",
      "Review: jill hey recently cleaned closet lots clothes give away interested hillary totally come sonia jill available wednesday afternoon around pm hillary yoga class time would evening ok jill going concert paul later really thursday time hillary ok jill sonia sonia finish classes would house maybe minutes later ok jill meet okay hillary ok sonia perfect thank jill see ya thursday \n",
      "Original summary: jill has clothes to give away sonia and will come to hers on thursday at \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0e69bf8de83c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-219f1da445c8>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;31m# 5. disabled static optimizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m       \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \"\"\"\n\u001b[0;32m--> 911\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mRangeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   3347\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3348\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.range()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3349\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3350\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3351\u001b[0m     variant_tensor = gen_dataset_ops.range_dataset(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_parse_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   3359\u001b[0m     \u001b[0;34m\"\"\"Parse arguments according to the same rules as the `range()` builtin.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_build_tensor\u001b[0;34m(self, int64_value, name)\u001b[0m\n\u001b[1;32m   3374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3375\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint64_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3376\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint64_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3378\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1321\u001b[0m           \u001b[0;34m\"%sConversion function %r for type %s returned non-Tensor: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m           (_error_prefix(name), conversion_func, base_type, ret))\n\u001b[0;32m-> 1323\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m       raise RuntimeError(\n\u001b[1;32m   1325\u001b[0m           \u001b[0;34m\"%sConversion function %r for type %s returned incompatible \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
